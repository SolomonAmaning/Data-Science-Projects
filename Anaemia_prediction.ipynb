{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18EcXlVNsNc2x9XCze4PEx08NQBtSsYvp",
      "authorship_tag": "ABX9TyPWEPYC6huAxR42UnfFisik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SolomonAmaning/Data-Science-Projects/blob/main/Anaemia_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Anemia Prediction\n",
        "In this project we have anemic and non-anemic images. We want to build a model on these images and observe how well the model predict the conjuctival images if they are anaemic or not. Our evaluation metrics will be imported from the sklearn.metrics library ('classification_report').\n",
        "\n",
        "We will use a deep learning model on the dataset. First we will import the two separate images and join them together and apply the deep learning model on it. We will tune hyperparameters to improve the accuracy"
      ],
      "metadata": {
        "id": "aApho239HX2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "from skimage.transform import resize\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score, roc_auc_score\n"
      ],
      "metadata": {
        "id": "MG6mdWn2I8VV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FQhD2pLuCDzZ"
      },
      "outputs": [],
      "source": [
        "# Import the images from the two folders\n",
        "anemic_folder = '//content/drive/MyDrive/Miscellaneous/Conjuctiva_images/Anemic'\n",
        "non_anemic_folder = '/content/drive/MyDrive/Miscellaneous/Conjuctiva_images/Non-anemic'\n",
        "\n",
        "anemic_images = []\n",
        "anemic_labels = []\n",
        "\n",
        "non_anemic_images = []\n",
        "non_anemic_labels = []\n",
        "\n",
        "# A loop to append label (1) as anemic\n",
        "for filename in os.listdir(anemic_folder):\n",
        "    im1 = Image.open(os.path.join(anemic_folder, filename)).convert('RGB').resize((256, 256))\n",
        "    # Normalize the image\n",
        "    im1 = np.array(im1)\n",
        "    im1 = im1 / 255\n",
        "\n",
        "    anemic_images.append(np.array(im1))\n",
        "    anemic_labels.append(1)\n",
        "\n",
        "for filename in os.listdir(non_anemic_folder):\n",
        "    im2 = Image.open(os.path.join(non_anemic_folder, filename)).convert('RGB').resize((256, 256))\n",
        "    # Normalize the image\n",
        "    im2 = np.array(im2)\n",
        "    im2 = im2 / 255\n",
        "    non_anemic_images.append(np.array(im2))\n",
        "    non_anemic_labels.append(0)\n",
        "\n",
        "\n",
        "anemic_images=np.array(anemic_images)\n",
        "non_anemic_images=np.array(non_anemic_images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((anemic_images, non_anemic_images))\n",
        "y = np.concatenate((anemic_labels, non_anemic_labels))"
      ],
      "metadata": {
        "id": "WVxU5--nYz9T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odVQO-zcBU7Z",
        "outputId": "cf4e2a68-b96f-4831-8473-7be5303c370e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "710"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9gbbEEkeq1s",
        "outputId": "d0a385c8-5f4d-4f35-e966-f860205601f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "710"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building "
      ],
      "metadata": {
        "id": "xSRyvp1MtnJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U82mMi5UgkfH",
        "outputId": "92796bd1-63a4-4607-c11e-10f0dffa299a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(710, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Using a deep learning algorithm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Defining  the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(X_train, y_train, epochs=16, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "3zg0r3xJOiv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c419d005-cb85-447e-865c-9fbe2b11b173"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "18/18 [==============================] - 10s 90ms/step - loss: 2.1750 - accuracy: 0.4982 - val_loss: 0.6301 - val_accuracy: 0.6620\n",
            "Epoch 2/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.6450 - accuracy: 0.6109 - val_loss: 0.6049 - val_accuracy: 0.6690\n",
            "Epoch 3/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.5825 - accuracy: 0.6796 - val_loss: 0.5649 - val_accuracy: 0.7394\n",
            "Epoch 4/16\n",
            "18/18 [==============================] - 1s 58ms/step - loss: 0.4972 - accuracy: 0.7465 - val_loss: 0.5140 - val_accuracy: 0.7254\n",
            "Epoch 5/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.3830 - accuracy: 0.8380 - val_loss: 0.4852 - val_accuracy: 0.7465\n",
            "Epoch 6/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.2874 - accuracy: 0.8662 - val_loss: 0.4675 - val_accuracy: 0.7606\n",
            "Epoch 7/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.2166 - accuracy: 0.9102 - val_loss: 0.4894 - val_accuracy: 0.7254\n",
            "Epoch 8/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.1568 - accuracy: 0.9489 - val_loss: 0.5075 - val_accuracy: 0.7535\n",
            "Epoch 9/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.1122 - accuracy: 0.9648 - val_loss: 0.5281 - val_accuracy: 0.7817\n",
            "Epoch 10/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0895 - accuracy: 0.9701 - val_loss: 0.5297 - val_accuracy: 0.7465\n",
            "Epoch 11/16\n",
            "18/18 [==============================] - 1s 58ms/step - loss: 0.0816 - accuracy: 0.9701 - val_loss: 0.6121 - val_accuracy: 0.7606\n",
            "Epoch 12/16\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0569 - accuracy: 0.9877 - val_loss: 0.7337 - val_accuracy: 0.7676\n",
            "Epoch 13/16\n",
            "18/18 [==============================] - 1s 56ms/step - loss: 0.0448 - accuracy: 0.9912 - val_loss: 0.6652 - val_accuracy: 0.7606\n",
            "Epoch 14/16\n",
            "18/18 [==============================] - 1s 57ms/step - loss: 0.0484 - accuracy: 0.9877 - val_loss: 0.6416 - val_accuracy: 0.7606\n",
            "Epoch 15/16\n",
            "18/18 [==============================] - 1s 60ms/step - loss: 0.0359 - accuracy: 0.9859 - val_loss: 0.6937 - val_accuracy: 0.7817\n",
            "Epoch 16/16\n",
            "18/18 [==============================] - 1s 60ms/step - loss: 0.0429 - accuracy: 0.9877 - val_loss: 0.7638 - val_accuracy: 0.7746\n",
            "5/5 [==============================] - 0s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classification report"
      ],
      "metadata": {
        "id": "5i3pF3FQY8TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the predictions to binary labels\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "\n",
        "# Evaluation Metrics\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(acc*100))\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \\n\", confusion_matrix)\n",
        "\n",
        "# Classification Report\n",
        "classification_report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report: \\n\", classification_report)\n",
        "\n",
        "# F1 Score\n",
        "f1_score = f1_score(y_test, y_pred)\n",
        "print(\"F1 Score: {:.2f}\".format(f1_score))\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "\n",
        "# ROC AUC Score\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(\"ROC AUC: {:.2f}\".format(roc_auc))\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds=metrics.roc_curve(y_test, y_pred)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "roc_auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHGBrP3Dx2An",
        "outputId": "ab4ca54b-24bb-485d-f0ea-8cd7f5243194"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 77.46%\n",
            "Confusion Matrix: \n",
            " [[31 18]\n",
            " [14 79]]\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.63      0.66        49\n",
            "           1       0.81      0.85      0.83        93\n",
            "\n",
            "    accuracy                           0.77       142\n",
            "   macro avg       0.75      0.74      0.75       142\n",
            "weighted avg       0.77      0.77      0.77       142\n",
            "\n",
            "F1 Score: 0.83\n",
            "Precision: 0.81\n",
            "Recall: 0.85\n",
            "ROC AUC: 0.74\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7410577134079439"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cfBYrg92Oi8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am yet to do hyperparameter tuning to improve model accuracy. I tried ensemble methods but it seems expensive.\n",
        "unless we buy gpu for that.\n"
      ],
      "metadata": {
        "id": "buktRtmGXN9g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4z5FavbXumS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}